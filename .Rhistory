model <- feols(as.formula(formula), data = data, weights = ~r_averagewk, cluster = ~get(cluster))
results[[y]] <- model
}
}
return(results)
}
# Regression variables
y_vars_3_11 <- paste0("w_r_", 3:11)
y_vars_15_20 <- c("w_r_15", "w_r_20")
# Run regressions for basic variables
reg_results_3_11 <- run_regressions(data, y_vars_3_11)
reg_results_15_20 <- run_regressions(data, y_vars_15_20)
# Add capital and materials
data <- data %>% mutate(lk = ifelse(is.na(lk), 0, lk), lm = ifelse(is.na(lm), 0, lm))
reg_results_capital <- run_regressions(data, c(y_vars_3_11, y_vars_15_20), extra_vars = "lk + lm + ")
# Filter public firms
data_public <- filter(data, f_public == 1)
reg_results_public <- run_regressions(data_public, c(y_vars_3_11, y_vars_15_20), extra_vars = "lk + lm + ")
# Add zmanagement and rerun regressions
data <- data %>% filter(!is.na(zmanagement)) %>%
mutate(zmanagement = scale(zmanagement))
reg_results_zmanagement <- run_regressions(data, c(y_vars_3_11, y_vars_15_20), extra_vars = "zmanagement + ")
# Load profits dataset and rerun
data_profits <- read_dta("/Users/diegomoers/Desktop/REPLICATION ASSIGNMENT/2017765data/Regressions/Accounts_matched_collapsed_profits.dta")
data_profits <- standardize_vars(data_profits, std_vars)
reg_results_profits <- run_regressions(data_profits, c(y_vars_3_11, y_vars_15_20), fixed_effects = "sic2", cluster = "sic2")
#save results
etable(reg_results_3_11, reg_results_15_20, reg_results_capital, reg_results_public, reg_results_zmanagement, reg_results_profits,
keep = c("ceo_behavior", "year_tenure", "::", "lemp"),
signif.code = c("*" = .1, "**" = .05, "***" = .01))
etable(reg_results_3_11, reg_results_15_20, reg_results_capital, reg_results_public, reg_results_zmanagement, reg_results_profits,
keep = c("ceo_behavior", "year_tenure", "lemp"),
signif.code = c("*" = .1, "**" = .05, "***" = .01))
etable(reg_results_3_11, reg_results_15_20, reg_results_capital, reg_results_public, reg_results_zmanagement, reg_results_profits,
keep = c("ceo_behavior", "year_tenure", "lemp"),
signif.code = c("*" = .1, "**" = .05, "***" = .01))
etable(reg_results_3_11, reg_results_15_20, reg_results_capital, reg_results_public, reg_results_zmanagement, reg_results_profits,
keep = c("ceo_behavior", "year_tenure", "lemp"),
signif.code = c("*" = .1, "**" = .05, "***" = .01))
# Load required libraries
library(fixest)
library(dplyr)
library(haven)
library(broom)
# Load the dataset
data <- read_dta("/Users/diegomoers/Desktop/REPLICATION ASSIGNMENT/2017765data/Regressions/Accounts_matched_collapsed.dta")
# Function to standardize variables
standardize_vars <- function(df, vars) {
for (var in vars) {
if (var %in% names(df)) {
df[[var]] <- as.numeric(scale(df[[var]]))
}
}
return(df)
}
# Define variables to standardize
std_vars <- c("ceo_behavior", grep("^w_r_", names(data), value = TRUE))
data <- standardize_vars(data, std_vars)
# Define function to run regressions
run_regressions <- function(data, y_vars, fixed_effects = "sic", cluster = "sic", extra_vars = "") {
results <- list()
for (y in y_vars) {
if (y %in% names(data)) {
formula <- paste0("ly ~ ", y, " + lemp + lempm + cons + active + ",
extra_vars, "factor(year) + factor(cty) + emp_imputed + ",
".[noise_basic_collapse] | ", fixed_effects)
model <- feols(as.formula(formula), data = data, weights = ~r_averagewk, cluster = ~get(cluster))
results[[y]] <- model
}
}
return(results)
}
# Regression variables
y_vars_3_11 <- paste0("w_r_", 3:11)
y_vars_15_20 <- c("w_r_15", "w_r_20")
# Run regressions for basic variables
reg_results_3_11 <- run_regressions(data, y_vars_3_11)
reg_results_15_20 <- run_regressions(data, y_vars_15_20)
# Add capital and materials
data <- data %>% mutate(lk = ifelse(is.na(lk), 0, lk), lm = ifelse(is.na(lm), 0, lm))
reg_results_capital <- run_regressions(data, c(y_vars_3_11, y_vars_15_20), extra_vars = "lk + lm + ")
# Filter public firms
data_public <- filter(data, f_public == 1)
reg_results_public <- run_regressions(data_public, c(y_vars_3_11, y_vars_15_20), extra_vars = "lk + lm + ")
# Add zmanagement and rerun regressions
data <- data %>% filter(!is.na(zmanagement)) %>%
mutate(zmanagement = scale(zmanagement))
reg_results_zmanagement <- run_regressions(data, c(y_vars_3_11, y_vars_15_20), extra_vars = "zmanagement + ")
# Load profits dataset and rerun
data_profits <- read_dta("/Users/diegomoers/Desktop/REPLICATION ASSIGNMENT/2017765data/Regressions/Accounts_matched_collapsed_profits.dta")
data_profits <- standardize_vars(data_profits, std_vars)
reg_results_profits <- run_regressions(data_profits, c(y_vars_3_11, y_vars_15_20), fixed_effects = "sic2", cluster = "sic2")
#save results
etable(reg_results_3_11, reg_results_15_20, reg_results_capital, reg_results_public, reg_results_zmanagement, reg_results_profits,
keep = c("ceo_behavior", "year_tenure", "lemp"),
signif.code = c("*" = .1, "**" = .05, "***" = .01))
# Inspect each regression object
str(reg_results_3_11)
str(reg_results_15_20)
str(reg_results_capital)
str(reg_results_public)
str(reg_results_zmanagement)
str(reg_results_profits)
# Combine all models into a list
all_models <- c(reg_results_3_11, reg_results_15_20, reg_results_capital,
reg_results_public, reg_results_zmanagement, reg_results_profits)
# Print each model's summary
for (i in seq_along(all_models)) {
cat("\n--- Model", i, "---\n")
print(summary(all_models[[i]]))
}
summary(reg_results_15_20)
################################################################################
################################################################################
########################      REPLICATION PCA/KMeans       #####################
################################################################################
################################################################################
# Load necessary libraries
library(dplyr)
library(tidyr)
# Read the CSV file
setwd("/Users/carmencilla/Desktop/Master EUR/Block 2/Data Science and HR Analytics/Replication Assignment/GROUP_ASSIGNMENT/")
ceo_data <- read.csv("survey_response_data.csv")
# Set 'id' as the row identifier
ceo_data <- ceo_data %>%
filter(level1 == 'interacting',
type != 'personal_family',
id != 1115) %>%
mutate(id = as.character(id))
# Function to create crosstabs
create_crosstab <- function(data, row_var, col_var, value_filter = NULL) {
if (!is.null(value_filter)) {
data <- data %>% filter(!!sym(col_var) != value_filter)
}
data %>%
count(!!sym(row_var), !!sym(col_var)) %>%
pivot_wider(names_from = !!sym(col_var), values_from = n, values_fill = 0)
}
df1 <- create_crosstab(ceo_data, "id", "F_duration")
df2 <- create_crosstab(ceo_data, "id", "F_planned", value_filter = "missing")
df3 <- create_crosstab(ceo_data, "id", "F_participants", value_filter = "missing")
ceo_data <- ceo_data %>%
mutate(
ins_alone = ifelse(ins == 1.0 & out == 0.0, 1, 0),
out_alone = ifelse(ins == 0.0 & out == 1.0, 1, 0),
ins_out = ifelse(ins == 1.0 & out == 1.0, 1, 0),
coordinate = ifelse(n_functions > 1, 1, 0),
activity_dummy = 1
)
df5a <- create_crosstab(ceo_data, "id", "out")
df_groupcom <- create_crosstab(ceo_data, "id", "groupcom")
df_bunits <- create_crosstab(ceo_data, "id", "bunits")
df_coo <- create_crosstab(ceo_data, "id", "coo")
df_cao <- create_crosstab(ceo_data, "id", "cao")
df6 <- create_crosstab(ceo_data, "id", "coordinate")
# Rename columns before joining
df5a <- df5a %>%
rename(out = `1`) %>%
select(id, out)
df6 <- df6 %>%
rename(coordinate2 = `1`) %>%
select(id, coordinate2)
df_groupcom <- df_groupcom %>%
rename(groupcom = `1`) %>%
select(id, groupcom)
df_bunits <- df_bunits %>%
rename(bunits = `1`) %>%
select(id, bunits)
df_coo <- df_coo %>%
rename(coo = `1`) %>%
select(id, coo)
df_cao <- df_cao %>%
rename(cao = `1`) %>%
select(id, cao)
# Aggregate data
agg_data <- data.frame(id = df1$id) %>%
left_join(df1, by = "id") %>%
left_join(df2, by = "id") %>%
left_join(df3, by = "id") %>%
left_join(df5a, by = "id") %>%
left_join(df_groupcom, by = "id") %>%
left_join(df_bunits, by = "id") %>%
left_join(df_coo, by = "id") %>%
left_join(df_cao, by = "id") %>%
left_join(df6, by = "id") %>%
replace(is.na(.), 0)
# Rename and mutate to create the desired variables
agg_data <- agg_data %>%
rename(
long = `1hrplus`,
planned = planned,
large = `two_plus_ppl`
) %>%
mutate(
coordinate1 = groupcom + bunits + coo + cao
) %>%
select(id, long, planned, large, out, coordinate1, coordinate2)
# Verify the renamed and mutated agg_data
print("Renamed and Mutated agg_data:")
print(head(agg_data))
# Calculate activities by summing 'activity_dummy' for each 'id'
activities <- ceo_data %>%
group_by(id) %>%
summarise(activity_dummy = sum(activity_dummy, na.rm = TRUE))
# Verify the activities dataframe
print("Activities:")
print(head(activities))
str(activities)
# Merge activities with agg_data and calculate shares
agg_data_share <- agg_data %>%
left_join(activities, by = "id") %>%
mutate(
long = long / activity_dummy,
planned = planned / activity_dummy,
large = large / activity_dummy,
out = out / activity_dummy,
coordinate1 = coordinate1 / activity_dummy,
coordinate2 = coordinate2 / activity_dummy
) %>%
# Remove the 'activity_dummy' column as it's no longer needed
select(-activity_dummy)
# Verify the agg_data_share dataframe
print("Aggregated Data Share:")
print(head(agg_data_share))
str(agg_data_share)
# Remove 'id' column for PCA as it's an identifier, not a feature
pca_data <- agg_data_share %>%
select(-id)
# Verify the PCA data
print("PCA Data:")
print(head(pca_data))
str(pca_data)
# Compute the correlation matrix
cor_matrix <- cor(pca_data, use = "complete.obs")
# Perform eigen decomposition on the correlation matrix
eig <- eigen(cor_matrix)
eig_vals <- eig$values
eig_vecs <- eig$vectors
# Print eigenvalues to understand the variance captured by each component
print("Eigenvalues:")
print(eig_vals)
# Determine the number of principal components to retain
# For example, retain components with eigenvalues > 1 or based on cumulative variance
# Here, we'll select the top 2 components as per your original Python code
# Order eigenvalues in decreasing order and get the indices of the top 2
ordered_indices <- order(eig_vals, decreasing = TRUE)[1:2]
# Extract the corresponding eigenvectors (principal components)
pca_components <- eig_vecs[, ordered_indices]
# Project the data onto the first two principal components
pca_scores <- as.matrix(pca_data) %*% pca_components
# Verify PCA scores
print("PCA Scores (First 6 Rows):")
print(head(pca_scores))
##K-MEANS
# Assuming 'agg_data' has been created as per previous steps
# Load necessary libraries
library(dplyr)
# Calculate the total count per CEO
agg_data$total_count <- rowSums(agg_data[, c('long', 'planned', 'large', 'out', 'coordinate1', 'coordinate2')])
# Prepare the data for k-means (exclude 'id' column)
kmeans_data <- agg_data_share %>%
select(-id)
# Set seed for reproducibility
set.seed(60)
# Perform k-means clustering
num_clusters <- 2
kmeans_result <- kmeans(kmeans_data, centers = num_clusters, nstart = 1)
# Extract the centroids
centroids <- kmeans_result$centers
# Extract the cluster labels
labels <- kmeans_result$cluster
# Extract the total within-cluster sum of squares (inertia)
inertia <- kmeans_result$tot.withinss
# Display the results
print("K-Means centroids:")
print(centroids)
print("K-Means labels (first 10):")
print(labels[1:10])
print(paste("K-Means total within-cluster sum of squares (inertia):", inertia))
################################################################################
################################################################################
####################      PCA EXPERIMENT       #################################
################################################################################
################################################################################
#Original analysis: 6 components (same method and commands as the rest to compare!!)
pca_result_6 <- prcomp(pca_data, scale. = TRUE)
biplot(pca_result_6, scale=0, main = "PCA Biplot (6 Components)")
######PCA WITH 4 COMPONENTS (from agg_data): long, planned, large, out##########
# Subset for PCA with 4 parameters (e.g., 'long', 'planned', 'large', 'out')
pca_data_4 <- agg_data_share %>%
select(long, planned, large, out)
# Verify the PCA data with 4 parameters
print("PCA Data with 4 Parameters:")
print(head(pca_data_4))
# Perform PCA
pca_result_4 <- prcomp(pca_data_4, scale. = TRUE)
# Print summary for variance explained
print("PCA with 4 Parameters Summary:")
summary(pca_result_4)
# Print the loadings (contributions of variables to the components)
print("PCA with 4 Parameters Loadings:")
print(pca_result_4$rotation)
# Plot Scree Plot
barplot(pca_result_4$sdev^2 / sum(pca_result_4$sdev^2),
main = "Scree Plot (4 Parameters)",
xlab = "Principal Component",
ylab = "Proportion of Variance Explained",
col = "skyblue")
print(pca_result_4)
#Important data about PCA 4 Components:
explained_variance <- (pca_result_4$sdev)^2
proportion_variance <- explained_variance / sum(explained_variance)
cumulative_variance <- cumsum(proportion_variance)
# Cumulative Variance Plot
plot(cumulative_variance,
type = "b",
main = "Cumulative Variance Explained (4 Parameters)",
xlab = "Number of Principal Components",
ylab = "Cumulative Proportion of Variance",
col = "darkblue", pch = 19)
#Scree plot
barplot(proportion_variance,
main = "Scree Plot (4 Components)",
xlab = "Principal Components",
ylab = "Proportion of Variance Explained",
col = "skyblue")
#Biplot PC1-PC2 and PC3-PC4
biplot(pca_result_4, scale = 0, choices = c(1, 2), main = "PCA Biplot (PC1 vs PC2)")
biplot(pca_result_4, scale = 0, choices = c(3, 4), main = "PCA Biplot (PC3 vs PC4)")
################PCA WITH 9 COMPONENTS (from agg_data)####################
###Creating New Variable 1.A.: market_relations. We need to create it in
# ceo_data and the use it for agg_data to perform PCA.
ceo_data <- ceo_data %>%
mutate(
market_relations = ifelse(
type %in% c("public_event", "workrelated_leisure", "business_meal") &
(clients == 1 | suppliers == 1 | banks == 1 | investors == 1 | dealers == 1 | compts == 1),
1,
0
)
)
#Group by id so that we can paste it to agg_data_share
market_relations_summary <- ceo_data %>%
group_by(id) %>%
summarise(market_relations = sum(market_relations, na.rm = TRUE) / n())
###Creating New Variable 1.b.: non_market_relations. We need to create it in
# ceo_data and the use it for agg_data to perform PCA.
ceo_data <- ceo_data %>%
mutate(
non_market_relations = ifelse(
type %in% c("public_event", "workrelated_leisure", "business_meal") &
(politicians == 1 | journalists == 1 | govoff == 1 ),
1,
0
)
)
#Group by id so that we can paste it to agg_data_share
non_market_relations_summary <- ceo_data %>%
group_by(id) %>%
summarise(non_market_relations = sum(non_market_relations, na.rm = TRUE) / n())
###Create New Variable 2: fixer
#Check the mean of the functions in the data set:
print(mean(ceo_data$n_functions)) ## 1.663325
#Therefore, we can establish "fixer" for 2 or more functions.
fixer <- ceo_data %>%
group_by(id) %>%
summarise(fixer = sum(n_functions > 2, na.rm = TRUE) / n())
#Fixer = proportion of activities that imply more than 2 activities per CEO.
#Note: ceo_data is a dataset of many observations per CEO. Agg_data_share is a measure per CEO
# that is, only 1 observation, aggregated/grouped by CEO. We add out new variables to agg_data_share:
agg_data_share <- agg_data_share %>%
left_join(fixer, by = "id") %>%
left_join(market_relations_summary, by = "id")  %>%
left_join(non_market_relations_summary, by = "id")
##PCA analysis for 9 variables
# Subset for PCA with 9 parameters
pca_data_9 <- agg_data_share %>%
select(long, planned, large, out, coordinate1, coordinate2, market_relations, non_market_relations, fixer)
# Verify the PCA data with 9 parameters
print("PCA Data with 9 Parameters:")
print(head(pca_data_9))
# Perform PCA
pca_result_9 <- prcomp(pca_data_9, scale. = TRUE)
#Scree plot for 9 components
barplot(pca_result_9$sdev^2 / sum(pca_result_9$sdev^2),
main = "Scree Plot (9 Components)",
xlab = "Principal Components",
ylab = "Proportion of Variance Explained",
col = "skyblue")
############  Eigenvalues for 9 components:
# Compute the correlation matrix
cor_matrix_9 <- cor(pca_data_9, use = "complete.obs")
print(cor_matrix_9)
# Perform eigen decomposition on the correlation matrix
eig_9 <- eigen(cor_matrix_9)
eig_vals_9 <- eig_9$values
eig_vecs_9 <- eig_9$vectors
# Print eigenvalues to understand the variance captured by each component
print("Eigenvalues PCA-9:")
print(eig_vals_9)
# Determine the number of components to retain based on eigenvalues > 1
num_components <- sum(eig_vals_9 > 1)
print(paste("Number of components with eigenvalues > 1:", num_components))
# Extract the indices of components with eigenvalues > 1
indices_to_retain <- which(eig_vals_9 > 1)
# Extract the corresponding eigenvectors (principal components)
pca_components_9 <- eig_vecs_9[, indices_to_retain]
# Project the data onto the retained principal components
pca_scores_9 <- as.matrix(pca_data_9) %*% pca_components_9
# Verify PCA scores
print("PCA Scores PCA 9 Components (First 6 Rows):")
print(head(pca_scores_9))
############  Eigenvalues for 4 components:
# Compute the correlation matrix
cor_matrix_4 <- cor(pca_data_4, use = "complete.obs")
print(cor_matrix_4)
# Perform eigen decomposition on the correlation matrix
eig_4 <- eigen(cor_matrix_4)
eig_vals_4 <- eig_4$values
eig_vecs_4 <- eig_4$vectors
# Print eigenvalues to understand the variance captured by each component
print("Eigenvalues PCA-4:")
print(eig_vals_4)
# Determine the number of components to retain based on eigenvalues > 1
num_components_4 <- sum(eig_vals_4 > 1)
print(paste("Number of components with eigenvalues > 1:", num_components_4))
# Extract the indices of components with eigenvalues > 1
indices_to_retain_4 <- which(eig_vals_4 > 1)
# Extract the corresponding eigenvectors (principal components)
pca_components_4 <- eig_vecs_4[, indices_to_retain_4]
# Project the data onto the retained principal components
pca_scores_4 <- as.matrix(pca_data_4) %*% pca_components_4
# Verify PCA scores
print("PCA Scores PCA 4 Components (First 6 Rows):")
print(head(pca_scores_4))
###########################  Export New Variables  ##############################
extension_indeces <- market_relations_summary %>%
left_join(non_market_relations_summary, by = "id") %>%
left_join(fixer, by = "id")
head(extension_indeces)
###########################  Presentation slides  ##############################
####Screeplot for eigenvalues!!!! PCA-9
#png("scree_plot_9.png", width = 800, height = 600) #Open graph and save it in figs folder.
bar_positions <- barplot(eig_vals_9,
main = "Scree Plot (9 Components)",
xlab = "Principal Component",
ylab = "Eigenvalue",
col = "skyblue")
# Kaiser Rule (horizontal line)
abline(h = 1, col = "red", lty = 2)
# Add eigenvalues over bars
text(x = bar_positions,
y = eig_vals_9,
labels = sprintf("%.2f", eig_vals_9),
pos = 3,  # Position over the bar
cex = 0.8,  # Font size
col = "black")  # Font color
#dev.off() #Closing the pdf graph.
####Screeplot for eigenvalues!!!! PCA-6
#png("scree_plot_6.png", width = 800, height = 600) #Open graph and save it in figs folder.
bar_positions <- barplot(eig_vals,
main = "Scree Plot (6 Components)",
xlab = "Principal Component",
ylab = "Eigenvalue",
col = "skyblue")
# Kaiser Rule (horizontal line)
abline(h = 1, col = "red", lty = 2)
# Add eigenvalues over bars
text(x = bar_positions,
y = eig_vals,
labels = sprintf("%.2f", eig_vals),
pos = 3,
cex = 0.8,
col = "black")
#dev.off() #Closing the pdf graph.
####Screeplot for eigenvalues!!!! PCA-4
#png("scree_plot_4.png", width = 800, height = 600) #Open graph and save it in figs folder.
bar_positions <- barplot(eig_vals_4,
main = "Scree Plot (4 Components)",
xlab = "Principal Component",
ylab = "Eigenvalue",
col = "skyblue")
# Kaiser Rule (horizontal line)
abline(h = 1, col = "red", lty = 2)
# Add eigenvalues over bars
text(x = bar_positions,
y = eig_vals_4,
labels = sprintf("%.2f", eig_vals_4),
pos = 3,
cex = 0.8,
col = "black")
#dev.off() #Closing the pdf graph.
##Export tables: loadings and summary
install.packages("writexl")
library(writexl)
# PCA Loadings
loadings_6 <- as.data.frame(pca_result_6$rotation)
#write_xlsx(loadings_6, "PCA_Loadings_6.xlsx")
# PCA Summary
explained_variance_9 <- (pca_result_9$sdev)^2  # Variance of each component
proportion_variance_9 <- explained_variance_9 / sum(explained_variance_9)  # Proportion explained
cumulative_variance_9 <- cumsum(proportion_variance_9)  # Cumulative variance
# Crear el dataframe del resumen
pca_summary_9 <- data.frame(
Component = paste0("PC", 1:length(eig_vals_9)),
Eigenvalue = eig_vals_9,
ProportionVariance = proportion_variance_9,
CumulativeVariance = cumulative_variance_9
)
# Imprimir el resumen
print(pca_summary_9)
write_xlsx(pca_summary_9, "PCA_Summary_9.xlsx")
